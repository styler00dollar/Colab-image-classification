print_training_epoch_end_metrics: False # RAM requirements for big datasets are high, disble it if you have big datasets. does not imply validation
use_amp: False
gpus: 0
use_swa: False
save_step_frequency: 5000

# calculate these with means_stds.py!
means: [0.7032, 0.6346, 0.6234]
std: [0.2520, 0.2507, 0.2417]

optimizer: AdamP # Adam | AdamP | SGDP | MADGRAD (pip install madgrad)
lr: 0.0001
batch_size: 2 # 62
aug: MuAugment # gridmix, cutmix, MuAugment, None
loss: normal # normal | CenterLoss
size: 256 # image size
precision: 32 # 32
max_epochs: 9999
progress_bar_refresh_rate: 20
default_root_dir: "/content/"

path:
  # pretrain
  pretrain:
  checkpoint_path: 

  training_path: '/content/data/' # input folder
  validation_path: '/content/data/' # validation folder
  test_path: '/content/data/' # validation folder / test.py
  log_path: "/content/logs/"
  checkpoint_save_path: "/content/" 


# which model architecture to train

# efficientnet-b0 up to efficientnet-b8 (pip install efficientnet_pytorch)
# mobilenetv3_small / mobilenetv3_large
# resnet50 / resnet101 / resnet152
# ViT / DeepViT
# RepVGG-A0, RepVGG-A1, RepVGG-A2, RepVGG-B0, RepVGG-B1, RepVGG-B1g2, RepVGG-B1g4, RepVGG-B2, RepVGG-B2g2, RepVGG-B2g4, RepVGG-B3, RepVGG-B3g2, RepVGG-B3g4
# squeezenet_1_0 / squeezenet_1_1
# vgg11, vgg13, vgg16, vgg19
# SwinTransformer

# for vgg and resnet
#pretrain: False

# timm
# pip install timm
# you can loop up models here: https://rwightman.github.io/pytorch-image-models/
# Example: "tf_efficientnetv2_s"
model_train: timm
model_choise: 'tf_efficientnetv2_b0'
#model_choise: "swin_tiny_patch4_window7_224"

#################

# other models with configurable parameters
#model_train: effV2
#conv: fft # fft | conv2d
#model_size: s # s | m | l | xl

# x-transformers
# pip install x-transformers
#model_train: x_transformers
#image_size: 512
#patch_size: 32
#dim: 512
#depth: 6
#heads: 8

# Warning: only 256px input (b110)
#model_train: mobilevit 
#model_size: xxs # xxs | xs | s

# because of too many parameters, a seperate config file named "hrt_config.yaml" is available
#model_train: hrt

# volo (2021) (224px)
#model_train: volo
#model_size: volo_d1 # volo_d1 up to volo_d5
#pretrain: False

# pvt_v2 (2021)
#model_train: pvt_v2
#model_size: pvt_v2_b0 # pvt_v2_b0 to pvt_v2_b5, pvt_v2_b2_li
#pretrain: False

# ConvMLP (2021)
#model_train: ConvMLP
#model_size: convmlp_s # convmlp_s | convmlp_m | convmlp_l
#pretrain: False

# FocalTransformer (2021)
#model_train: FocalTransformer

# MobileFormer (2021)
#model_train: mobile_former
#model_size: config_52 # config_52 | config_294 | config_508

#################

num_classes: 2 # Warning: Some do require amount classes + 1 as num_classes. 
diffaug_activate: False
policy: 'color,translation' # [color,translation,cutout]
num_workers: 12

################################################################
# inference
# args for sort.py / test.py (only supports efficientnet)
resize_method: PIL # PIL | OpenCV
model_path: '/content/model.pth'
path0: '/content/0'
path1: '/content/1'