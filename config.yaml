print_training_epoch_end_metrics: False # RAM requirements for big datasets are high, disble it if you have big datasets. does not imply validation
use_amp: False
gpus: 1
use_swa: False
save_step_frequency: 25000

# calculate these with means_stds.py!
means: [0.7032, 0.6346, 0.6234]
std: [0.2520, 0.2507, 0.2417]

lr: 0.0001
batch_size: 8
aug: # gridmix, cutmix, CenterLoss, None
size: 512 # image size
precision: 32 # 32
max_epochs: 9999
progress_bar_refresh_rate: 20
default_root_dir: '/experiment2/'

path:
  # pretrain
  pretrain: "Checkpoint_1_913435_loss_0.223359_acc_0.914601_D.pth"
  checkpoint_path: 

  training_path: '/dataset/' # input folder
  validation_path: '/val_png/' # validation folder
  test_path: '/val_png/' # validation folder / test.py
  log_path: '/experiment2/logs/'
  checkpoint_save_path: '/experiment2/'


# which model architecture to train

# efficientnet-b0 up to efficientnet-b8
# mobilenetv3_small / mobilenetv3_large
# resnet50 / resnet101 / resnet152
# ViT / DeepViT
# RepVGG-A0, RepVGG-A1, RepVGG-A2, RepVGG-B0, RepVGG-B1, RepVGG-B1g2, RepVGG-B1g4, RepVGG-B2, RepVGG-B2g2, RepVGG-B2g4, RepVGG-B3, RepVGG-B3g2, RepVGG-B3g4
# squeezenet_1_0 / squeezenet_1_1
# vgg11, vgg13, vgg16, vgg19
# SwinTransformer

# timm
# pip install timm
# you can loop up models here: https://rwightman.github.io/pytorch-image-models/
# Example: "tf_efficientnetv2_s"
timm: True

model_train: 'tf_efficientnetv2_b0'

num_classes: 3 # Warning: Some do require amount classes + 1 as num_classes. 
diffaug_activate: False
policy: 'color,translation' # [color,translation,cutout]
num_workers: 12

################################################################
# inference
# args for sort.py / test.py (only supports efficientnet)
resize_method: PIL # PIL | OpenCV
model_path: '/content/model.pth'
path0: '/content/0'
path1: '/content/1'