print_training_epoch_end_metrics: False # RAM requirements for big datasets are high, disble it if you have big datasets. does not imply validation
gpus: 1
use_swa: True
compile: False
lr_finder: False
max_epochs: 200
save_step_frequency: 10000

# calculate these with means_stds.py!
means: [0.7032, 0.6346, 0.6234]
std: [0.2520, 0.2507, 0.2417]

# ffcv requires 0-255
#means: [179.316, 161.823, 158.967]
#std: [64.26, 63.9285, 61.6335]

optimizer: adan # adam | adan | adamw_sf | adamw_win | adan_sf | lamb
lr: 0.001
batch_size: 5
cutmix_or_mixup: true
size: 448 # 256 # image size
precision: 16-mixed # 16-mixed | 16-true | 32 | 32-true | bf16 | transformer-engine | transformer-engine-float16
progress_bar_refresh_rate: 20
default_root_dir: "/"
img_reader: OpenCV # turboJPEG | OpenCV

ffcv: false

path:
  # pretrain
  pretrain: 
  checkpoint_path: 

  training_path: '/'
  validation_path: '/'
  test_path: '/'
  log_path: "/"
  checkpoint_save_path: "/"

  # only for ffcv
  beton_path: ./data/images.beton

# which model architecture to train

# timm
# pip install timm
# you can loop up models here: https://rwightman.github.io/pytorch-image-models/
# Example: "tf_efficientnetv2_s"
#model_train: timm
#model_choise: 'tf_efficientnetv2_b0'
#model_choise: "swin_tiny_patch4_window7_224"
#model_choise: "eva02_large_patch14_448.mim_m38m_ft_in22k_in1k"

#################

model_train: effV2
# fft | conv2d | FastKANConv2DLayer | KACNConv2DLayer | BottleNeckKAGNConv2DLayer | KAGNConv2DLayer
# KAGNConv2DLayerV2 | KAJNConv2DLayer | KALNConv2DLayer | KANConv2DLayer | WavKANConv2DLayer
conv: conv2d 
model_size: s # s | m | l | xl

# x-transformers
# pip install x-transformers
#model_train: x_transformers
#image_size: 512
#patch_size: 32
#dim: 512
#depth: 6
#heads: 8

# Warning: only 256px input (b110)
#model_train: mobilevit 
#model_size: xxs # xxs | xs | s

# because of too many parameters, a seperate config file named "hrt_config.yaml" is available
#model_train: hrt

# volo (2021) (224px)
#model_train: volo
#model_size: volo_d1 # volo_d1 up to volo_d5
#pretrain: False

# pvt_v2 (2021)
#model_train: pvt_v2
#model_size: pvt_v2_b0 # pvt_v2_b0 to pvt_v2_b5, pvt_v2_b2_li
#pretrain: False

# ConvMLP (2021)
#model_train: ConvMLP
#model_size: convmlp_s # convmlp_s | convmlp_m | convmlp_l
#pretrain: False

# FocalTransformer (2021)
#model_train: FocalTransformer

# MobileFormer (2021)
#model_train: mobile_former
#model_size: config_52 # config_52 | config_294 | config_508

# poolformer (2021)
#model_train: poolformer
#model_size: poolformer_s12 # poolformer_s12 | poolformer_s24 | poolformer_s36 | poolformer_m36 | poolformer_m48

# next vit (2022)
#model_train: next_vit
#model_size: small # small | base | large

# hornet
#model_train: hornet
#model_size: hornet_tiny_7x7 # hornet_tiny_7x7 | hornet_small_7x7 | hornet_small_gf | hornet_base_7x7 | hornet_base_gf

# moganet
#model_train: moganet
#model_size: moganet_xtiny_1k # moganet_xtiny_1k | moganet_tiny_1k | moganet_tiny_1k_sz256 | moganet_small_1k | moganet_base_1k | moganet_large_1k

# efficientvit (2023) (224px)
#model_train: efficientvit
#model_size: m5 # m0, m1, m2, m3, m4, m5 
#################

num_classes: 2 # Warning: Some do require amount classes + 1 as num_classes. 
diffaug_activate: False
policy: 'color,translation' # [color,translation,cutout]
num_workers: 12
